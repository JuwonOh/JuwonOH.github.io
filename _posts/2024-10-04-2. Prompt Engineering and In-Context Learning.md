---
title: "2. Prompt Engineering and In-Context Learning"
excerpt: "LLM의 prompt에 대한 설명과 prompt engineering에 대한 소개"
Category: 
    - Study
tags:
    - [NLP, LLM, Prompt]
roc: true
toc_sticky: true

data: 2024-10-04
last_modified_at: 2024-10-04
---


## Prompt

- **정의: 사용자가 생성형 모델에 보내는 입력.**
    - AI 모델이 주어진 **역할을 수행하는데 필요한 지침, context, 제약조건** 등을 의미함.
- 대부분의 생성형 ai는 다양한 양식의 데이터를 받지만 **대부분의 경우 텍스트 인풋을 입력값으로 받음.**
    - **Tex tGenration task**
        - 정의: **특정한 text가 주어졌을때, 다음 task를 생성해 내는 task**
        - Tak에 대한 설명: https://huggingface.co/tasks/text-generation
- 예시
    - “다음 텍스트를 요약하세요”
    - “2016년 world series에서 우승한 팀은 어딘가요?”
- 주의 사항
    - prompt의 양식이 항상 text로 국한되지는 않음.
    - 모델에 따라서 text 이외의 입출력을 사용할 수 있는 경우도 있음.
    

### Token

- **NLP에서 token이 중요한 이유**
    - **생성형 모델**이 작업하는 **task는 전부 token를 기반으로 이루어짐.**
        - LLM이 입력받고, 출력하는 대상은 전부 token들이다.
        - 대부분의 **생성형 모델의 task count도 token을 기반으로 이루어짐.**
            - GPT4/Claude 등의 사이트에서 api 요금은 전부 token의 수로 이루어짐.
            - Opensource LLM 들도 대부분 LLM이 받을 수 있는 max token을 명시함.
    - 일반적으로 **LLM이 특정한 task를 수행하지 못하면, 거기에 대한 충분한 tokenizer가 없기 때문임**(by **Andrej Karpathy: [Let's build the GPT Tokenizer](https://www.youtube.com/watch?v=zduSFxRajkE&ab_channel=AndrejKarpathy))**
        - LLM이 특정한 문제를 일으키면 tokenization에서 문제가 있을 가능성이 있음.
            
            ![image.png](https://prod-files-secure.s3.us-west-2.amazonaws.com/0b6e8011-95fb-4609-bdc4-cea77f620d5e/94157966-7c8d-45aa-8992-a1ea2f44eba9/image.png)
            
        - GP4는 특정한 단어내에 있는 r의 갯수도 맞추지 못함. → tokenizer 때문에.
            - https://community.openai.com/t/incorrect-count-of-r-characters-in-the-word-strawberry/829618
- **llm 이 인식하는 token은 우리가 일반적으로 말하는 token과 다름.**
    - LLM은 모델이 **학습한 tokenizer를 기반으로 입출력을 이해함.**
    - LLM이 의존하는 **subword units(ex. byte-pair-encoding)/unigram language model** 기반 **tokenizer의 특성상 1개의 word여도 n개의 token으로 나올 수 있음.**
        - LLM이 학습한 text에 기반하여 tokenizer를 생성하기에 이런 경향이 두드러짐.
        - 한국어의 경우 어근에 접사가 결합되는 굴절어의 경향이 더해저 이런 경향이 더 강하게 나타남.
            
            ![image.png](https://prod-files-secure.s3.us-west-2.amazonaws.com/0b6e8011-95fb-4609-bdc4-cea77f620d5e/cc0f6df5-a452-401c-bbc4-beee40b68dc0/image.png)
            

## Prompt Enginnering/Structure

### Prompt Format

- 모델마다 서로 다른 prompt format를 가짐
    - [Llama3-instruct의 프롬프트 양식](https://www.llama.com/docs/model-cards-and-prompt-formats/meta-llama-3/)
        
        ```xml
        <|begin_of_text|><|start_header_id|>system<|end_header_id|>
        
        You are a helpful AI assistant for travel tips and recommendations<|eot_id|>
        
        <|start_header_id|>user<|end_header_id|>
        
        What can you help me with?<|eot_id|><|start_header_id|>assistant<|end_header_id|>
        ```
        
- **프롬프트 구조가 함의하는 것**
    - 개별 모델은 **학습 방식에 따라서 서로 상이한 prompt format를 가짐.**
    - 모델이 변경될 경우 prompt를 사용할 때, prompt format을 확인하고, 사용하는 게 좋음.

### Prompt Structure

- **instruction**
    - **기능: 모델에 수행하려는 작업을 설명하는 글**
    - 예시
        
        ![image.png](https://prod-files-secure.s3.us-west-2.amazonaws.com/0b6e8011-95fb-4609-bdc4-cea77f620d5e/5b39e526-66f7-4969-a2ea-59bf4f6ea922/image.png)
        
    - **instruction을 더 잘 작성하기 위한 방법**
        - AI 모델에 **효과적인 지침을 작성하기 위해서는 명확성, 구체성, 맥락성이 있으면 좋음.**
        - 하지만 **간단하고 이해하기 쉬워야 함.**
        - 작업을 수행하기 위한 **context를 넣어주면 모델이 작업과 주제를 더 잘 이해할 수 있음.**
- **Context**
    - 정의: 모델이 **작업과 주제를 더 잘 이해하고, 응답하기 위해서 필요한 정보**를 의미함.
    - 예시: **이전 대화의 정보, 배경 정보, 특정 사용자의 요청에 대한 개인화된 정보.**
    - 필요한 이유: **모델의 답을 사용자가 원하는 방향으로 유도**하기 위해서.

### Few-shot leaning

- 정의: **context에 instruction을 수행하는데 필요한 정보를 제공하는 방법**
- 예시
    
    ![image.png](https://prod-files-secure.s3.us-west-2.amazonaws.com/0b6e8011-95fb-4609-bdc4-cea77f620d5e/de52754f-fd7f-44f3-ad4a-676831536dbe/image.png)
    
- **장점**
    - **Finetuning을 하지 않아도 됨**
        - resource가 많이 드는 finetuning을 하지 않아도 사용자가 원하는 context를 넣어주는 방식으로 model을 사용하게 됨.(ex RAG)
    - **output 형태를 사용자가 원하는 대로 조절할 수 있음.**
- **주의사항**
    - model은 저마다의 max_token_size가 있음. → **context가 길어지면 모델이 받을 수 있는 token을 소모하게 됨.**
    - 문제를 해결하는데 **꼭 필요한 context를 넣어주는게 중요함.**
        - **context가 insturcution과 관련이 없거나 이상한 경우 context를 주입하지 않는 것만 못한 상황이 야기될 수 있음.**
    - 일반적으로 **규모가 더 큰 모델일 수록 context을 종합해서 일반화된 추론을 할 수 있음.**
        
        → Parameter size가 작으면, context를 주입해도 의도한 결과를 내지 못하는 경우가 꽤나 있음.
        
- few-shot leaning을 사용할 때 더 나은 성과를 보이는 이유
    
    → 대부분의 **언어모델은 in-context(fewshot) leanring을 기반으로 학습이 되어 있음.**
    
    - [**Language Models are Few-Shot Learners**](https://arxiv.org/abs/2005.14165)

### Prompt를 잘 작성하는 방법

- **명확하고 간결하게 작성하기**
- 창의력을 발휘하기(?)
- context의 양이 너무 많을 경우 prompt의 맨 뒤에 두기
    - 예시
        
        ![image.png](https://prod-files-secure.s3.us-west-2.amazonaws.com/0b6e8011-95fb-4609-bdc4-cea77f620d5e/ff1e0c96-ecd7-4bc0-acd3-a66b7b71a3b3/image.png)
        
    - 언어모델은 context의 맨앞과 뒤에 더 큰 영향을 받는 경향이 있음.
        - [Lost in the middle](https://arxiv.org/abs/2307.03172)
            
            ![image.png](https://prod-files-secure.s3.us-west-2.amazonaws.com/0b6e8011-95fb-4609-bdc4-cea77f620d5e/1d6b5288-2606-4964-a1e2-ccfa7d46a48c/image.png)
            
- **주제를 더 명확하게 전달하기**
    - 누가, 어떤걸, 어디서, 언제, 왜, 어떻게 등을 명시하여 설명
- **명시적 지시문 사용하기**
    - 특정 형식으로 출력되게 하려면 출력도 명시하는게 좋음.
    - 예시: 한문장으로 요약해주세요.
- **부정적인 표현을 사용하지 않기**
    - 언어모델은 부정적인 표현에 대부분 약함
    - 예시
        - Summarize in 5 sentences or less” → “Summarize in no
        more than 5 sentences.”
- Context나 짧은 예시 프롬프트 포함하기
- **응답할 때 크기/양을 지정하기**
    - 예시: “List the top 3 complaints from the following customer-support
    conversation:”
- **구체적인 응답 형식을 입력하기**
    - 대괄호 같은 문장 부호 사용하게 하기
        - 요즘은 전부 다 **XML 양식이나 python 양식(pydantic)으로 하는게 유행.**
    - 예시: “Summarize this document article in 10 words or less as shown here:
    [New generative AI model beats X benchmark by Y %.]”
- **환각을 피하기 위해서 자신없을 경우 응답할 값을 지정하기.**
    - 예시
        
        ![image.png](https://prod-files-secure.s3.us-west-2.amazonaws.com/0b6e8011-95fb-4609-bdc4-cea77f620d5e/905db4e5-e456-4a10-a2b5-f11cac011048/image.png)
        
- **“단계적으로 생각해보기”라고 요청하기**
    - 예시
        
        ![image.png](https://prod-files-secure.s3.us-west-2.amazonaws.com/0b6e8011-95fb-4609-bdc4-cea77f620d5e/00628074-216c-4556-a89c-2bfd926d7c27/image.png)
        
    - [Chain of Thought](https://arxiv.org/abs/2201.11903)
        - 정의: 문제를 해결할 때 필요한 일련의 논리적 단계를 Context로 명시해주는 방법.
        - 참고할 만한 방법들
            - 세부 작업으로 분리하기: “divide into subtasks”
            - 체계적으로 접근하기: “approach the problem systematically”
            - 한번에 한 단계씩 문제를 추론하기“reason through the problem one step at a time”
- **제약조건을 추가하기**
    - 길이, 형식, 포함된 정보, 제외된 정보 등을 기준으로 응답 제한하기
    - 예시:“Summarize this process in exactly 5 steps:”
- **모델이 응답해서는 안되는 프롬프트는 피하거나, 고지사항을 사용하기**
    - Model의 harmfulness 등이나 Bias에 대한 부분과도 맞닿아 있음.
- **Prompt에 XML, HTML tag 사용하기**
    - **Prompt의 구조를 모델이 이해하기 쉬운 방식으로 제공**하는게 필요함.
    - tag를 지정해서 **context를 구조화 하면 model이 더 prompt를 쉽게 이해할 수 있음.**
- 특정한 부분을 집중하게 하기
    - 입력 text의 특정한 부분에 집중하게 요청할 수 있음.
- **개인정보 masking하기**
    - **LLM으로 prompt를 쓰면 개인정보를 쉽게 마스킹 할 수 있음.**

- **지속적인 실험과 검증이 필요함.**
    - Prompt를 개선하기 위해서는 사용자가 직접 실험을 지속적으로 해야함.
- **prompt를 작성하는 것도 자동화 할 수도 있음.**
    - 응답 평가하기
        - 사용자가 만족할 수 있는 성능이 나오는지 응답을 평가할 수 있어야 함.
        - 자동화된 답변 평가는 매우 다양한 방법이 있음.
            - https://arxiv.org/abs/2303.16634
            - https://arxiv.org/abs/2309.15217
            - https://arxiv.org/abs/2306.05685
    - **정리**
        - 준비물: RAG pipeline, 질문/정답 데이터 셋
        - 원리: 유저가 LLM의 답변에 feedback을 주면, LLM이 feedback을 기반으로 prompt를 개선하는 task를 반복
            - https://prompt-optimizer.streamlit.app/
        - 출처
            
            https://www.youtube.com/watch?v=z0c2BcTnYpY&t=358s&ab_channel=테디노트TeddyNote
            

## Inference Configuration Parameter

- **기능: 모델의 응답길이와 창의성을 조절할 수 있는 parameter**
- 종류
    - **max_new_token**
    - **greedy & random sampling**
    - **sample_top_k, sample**
    - **temperature**

### Max New Token

- 기능: 모델이 **생성하는 새 토큰의 수를 제한**함
- 필요한 이유
    - 모델이 **rambling하는 것을 강제로 막기 위해서**
        - rambling: 모델이 계속 말을 반복하는 것을 의미
            - 예시: https://discuss.huggingface.co/t/how-do-i-avoid-llm-rambling/84922
            - 발생하는 이유: **모든 모델은 tokenizer에 명시된 eot(end of token)을 만나거나, max token에 도달 할 때까지 text를 생성함.**
    - 모델이 사용하는 token은 항상 추가적인 resource와 latancy를 야기함.
- 주의 사항
    - max new token은 환각을 방지하는 방법이 아니라, **가리는 방법에 가까움.**
        
        → LLM의 답변이 Max new token에 도달하는 상황 자체가 좋은 상황이 아님.
        

### Greedy versus Random Sampling

- 언어 모델의 task
    - 대부분의 언어모델이 하는 task는 “**기존의 단어집합 (X)가 있을때, 특정한 단어가(y) 다음에 나올 확률”을 계산하는 작업**
        
         
        
        !https://jiho-ml.com/content/images/2020/04/figure1.png
        

- **Greedy sampling**
    - 정의: **다음에 올 단어(y)를 단어 행렬(Y)에서 가장 확률이 높은 단어를 선택**하자.
    - 단점: 짧은 sequence에서는 꽤나 잘 작동하지만**, 동일한 token sequence가 반복되는 경향**이 있음.
- **Random Sampling**
    - 정의: 언어모델이 계산한 **토큰 확률 분포 p(Y|X)을 반영해서 다음 token을 선택하자**.
    - 예시
        
        ![image.png](https://prod-files-secure.s3.us-west-2.amazonaws.com/0b6e8011-95fb-4609-bdc4-cea77f620d5e/7e48c791-14d0-469a-bbfd-c8259798c145/image.png)
        
        - Greedy: 항상 learns
        - Random: **토큰 확률 분포 p(Y|X)을 반영 → student가 0.02면 2%로 나옴**
    - 장점: **Text complete task에서 token이 무한 반복될 가능성을 줄일 수 있음.**
    - 단점: 모델의 결과가 **지나치게 창의적이거나 이해할 수 없는 답변이 나올 수도 있음.**
    
    - **Sampling 방법**
        - **Top-k**
            - 기능: 가장 **확률이 높은 k의 token에서 무작위로 토큰을 사용하도록 제한함.**
                - k=1이면 greedy와 동일함
        - **Top-p**
            - 기능: **P(Y|X)를 내림차순으로 정렬한 뒤에, 누적확률이 p를 초과하지 않는 token의 하위 집합을 선택함.**
            - 장점: 더 큰 **변동성을 생성할 수 있으며, Top-k를 선택하기 어려울때 사용**함.
        - 조합: 두 **변수 모두를 동시에 사용할 수도 있음.**
    
    ### Temperature
    
    - 정의: **토큰 확률 분포의 모양을 수정해서 모델 출력의 무작위성을 제어하는 방법**
    - 기능: **0~1사이의 값을 가지며 0에 가까울 수록 무작위성이 낮아지고, 1에 가까울 수록 무작위성이 높아진다.**
        
        ![image.png](https://prod-files-secure.s3.us-west-2.amazonaws.com/0b6e8011-95fb-4609-bdc4-cea77f620d5e/cea0f09e-7fb4-4d5d-97c3-3214541ed5d6/image.png)
        
    - 주의사항
        - 온도를 1부터 시작해서 조절하는 방법이 좋다.
        - task마다 권장되는 temperature가 다를 수 있음.
            - 정확한 답이 필요한 task나 LLM 모델에 학습된 token의 수가 적을 경우 temperature가 높은게 큰 문제를 야기할 수 있음.